---
name: CI/CD Pipeline

# Workflow triggers
on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:  # Allow manual triggering

# Global environment variables available to all jobs
env:
  NODE_VERSION: '22'  # Minimum supported version per package.json
  PYTHON_VERSION: '3.11'
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  DEPLOY_TIMEOUT: '300'
  CACHE_VERSION: 'v1'

# Concurrency settings to prevent multiple deployments
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: ${{ github.ref != 'refs/heads/main' }}

# Default settings for all jobs
defaults:
  run:
    shell: bash
    working-directory: .

# Job definitions with dependencies
jobs:
  # ========================================
  # LINT JOB - Code quality and standards
  # ========================================
  lint:
    name: Code Quality Check
    runs-on: ubuntu-latest
    timeout-minutes: 10

    permissions:
      contents: read
      pull-requests: write  # For PR comments

    outputs:
      lint-passed: ${{ steps.lint-check.outcome }}
      warnings-count: ${{ steps.lint-results.outputs.warnings }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better analysis

      - name: Setup environment
        uses: ./.github/actions/setup
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache-key-prefix: 'lint'

      - name: Run ESLint
        id: eslint
        run: |
          set +e  # Don't exit on error
          pnpm run lint
          EXIT_CODE=$?
          set -e  # Re-enable exit on error
          echo "eslint_exit_code=$EXIT_CODE" >> "$GITHUB_ENV"
          # ESLint returns 1 for errors, 0 for success (even with warnings)
          if [ $EXIT_CODE -eq 1 ]; then
            echo "eslint_failed=true" >> "$GITHUB_ENV"
            echo "ESLint found errors"
          else
            echo "ESLint passed (may have warnings)"
          fi
        continue-on-error: true

      - name: Run TypeScript type checking
        id: typecheck
        run: |
          set +e  # Don't exit on error
          pnpm run typecheck
          EXIT_CODE=$?
          set -e  # Re-enable exit on error
          echo "typecheck_exit_code=$EXIT_CODE" >> "$GITHUB_ENV"
          # TypeScript returns non-zero for errors
          if [ $EXIT_CODE -ne 0 ]; then
            echo "typecheck_failed=true" >> "$GITHUB_ENV"
            echo "TypeScript found errors"
          else
            echo "TypeScript type checking passed"
          fi
        continue-on-error: true

      - name: Security audit
        id: security
        run: pnpm audit --audit-level=moderate
        continue-on-error: true

      - name: Lint check summary
        id: lint-check
        run: |
          if [[ "${{ env.eslint_failed }}" == "true" ]] || \
             [[ "${{ env.typecheck_failed }}" == "true" ]]; then
            echo "âŒ Linting or type checking failed"
            exit 1
          else
            echo "âœ… All linting and type checks passed"
          fi

      - name: Process lint results
        id: lint-results
        if: always()
        run: |
          # For now, just report success/failure since we're using pnpm lint
          if [[ "${{ steps.eslint.outcome }}" == "success" ]]; then
            echo "warnings=0" >> "$GITHUB_OUTPUT"
            echo "No linting warnings"
          else
            echo "warnings=1" >> "$GITHUB_OUTPUT"
            echo "Linting issues found"
          fi

      - name: Comment PR
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const warnings = '${{ steps.lint-results.outputs.warnings }}';
            const passed = '${{ steps.lint-check.outcome }}' === 'success';

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## ðŸ” Lint Results\n\n${passed ? 'âœ… All checks passed!' : 'âŒ Some checks failed'}\n\nWarnings found: ${warnings}`
            });

  # ========================================
  # TEST JOB - Run all test suites with Node version matrix
  # ========================================
  test:
    name: Test Suite (Node ${{ matrix.node-version }})
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: lint  # Only run after lint passes

    permissions:
      contents: read
      checks: write  # For test reporting

    strategy:
      matrix:
        node-version: ['22', '24']  # Application requires Node >=22.15.32
      fail-fast: false

    env:
      CI: true
      NODE_ENV: test

    outputs:
      coverage: ${{ steps.coverage.outputs.percentage }}
      test-results: ${{ steps.test-summary.outputs.results }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup environment
        uses: ./.github/actions/setup
        with:
          node-version: ${{ matrix.node-version }}
          cache-key-prefix: 'test'

      - name: Create test environment
        run: |
          cp .env.example .env.test || true
          cat > .env.test << EOF
          NODE_ENV=test
          PORT=9999
          LOG_LEVEL=silent
          DATABASE_URL=file:test.db

          # Analytics settings
          ENABLE_ANALYTICS=false
          ANALYTICS_RETENTION_DAYS=30

          # Rate limiting settings (disabled for testing)
          RATE_LIMIT_ENABLED=false

          # JWT Authentication (for testing)
          JWT_SECRET=test-super-secret-jwt-key-32-characters-minimum-length-required
          JWT_EXPIRES_IN=1h
          JWT_REFRESH_SECRET=test-super-secret-refresh-jwt-key-32-characters-minimum-length
          JWT_REFRESH_EXPIRES_IN=24h

          # Better Authentication
          BETTER_AUTH_URL=http://localhost:9999
          BETTER_AUTH_SECRET=deep-secret-key-for-testing-test-super-secret-jwt-key-32-characters-minimum-length-required

          RESEND_API_KEY=re_test_mock_api_key_for_testing_only
          EOF

      - name: Setup database schema
        run: pnpm drizzle-kit push

      - name: Run tests with coverage
        id: run-tests
        run: pnpm run test:coverage

      - name: Generate coverage report
        id: coverage
        if: always() && steps.run-tests.outcome != 'cancelled'
        run: |
          # Check if coverage directory exists
          # Correct path to the coverage directory
          COVERAGE_DIR="src/coverage"

          # Check if the correct directory exists
          if [ -d "$COVERAGE_DIR" ]; then
              echo "coverage_exists=true" >> "$GITHUB_OUTPUT"

              # Try to extract coverage percentage from the correct path
              if [ -f "$COVERAGE_DIR/coverage-summary.json" ]; then
                # Use jq to parse the JSON file at the correct location
                coverage=$(jq -r '.total.lines.pct // "0"' "$COVERAGE_DIR/coverage-summary.json" 2>/dev/null || echo "0")
                echo "percentage=$coverage" >> "$GITHUB_OUTPUT"
                echo "Code coverage: $coverage%"
              else
                echo "percentage=0" >> "$GITHUB_OUTPUT"
                echo "Coverage summary not found in $COVERAGE_DIR"
              fi
          else
              echo "coverage_exists=false" >> "$GITHUB_OUTPUT"
              echo "percentage=0" >> "$GITHUB_OUTPUT"
              echo "No coverage data generated"
          fi

      - name: Upload coverage artifact
        if: steps.coverage.outputs.coverage_exists == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-node-${{ matrix.node-version }}
          path: |
            src/coverage/
            !src/coverage/tmp/
          retention-days: 7

      - name: Upload coverage to Codecov
        if: steps.coverage.outputs.coverage_exists == 'true' && matrix.node-version == '22'
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./src/coverage/lcov.info
          flags: unittests
          name: codecov-node-${{ matrix.node-version }}
          fail_ci_if_error: false

      - name: Test summary
        id: test-summary
        if: always()
        run: |
          echo "results=${{ steps.run-tests.outcome }}" >> "$GITHUB_OUTPUT"
          echo "Test suite with Node ${{ matrix.node-version }}: ${{ steps.run-tests.outcome }}"

  # ========================================
  # DEPLOY JOB - Trigger deployment workflow
  # ========================================
  deploy:
    name: Trigger Deployment
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [lint, test]  # Only run after both lint and test pass
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'

    permissions:
      contents: read
      actions: write  # For triggering workflow
      statuses: write  # For creating commit status

    outputs:
      deployment-triggered: ${{ steps.trigger-deploy.outputs.triggered }}

    steps:
      - name: Trigger deployment workflow
        id: trigger-deploy
        uses: actions/github-script@v7
        with:
          script: |
            const result = await github.rest.actions.createWorkflowDispatch({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'deploy.yml',
              ref: 'main'
            });

            console.log('âœ… Deployment workflow triggered successfully');
            core.setOutput('triggered', 'true');

            return result;

      - name: Notify deployment trigger
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha: context.sha,
              state: 'pending',
              description: 'Deployment workflow triggered',
              context: 'deployment/trigger'
            });
